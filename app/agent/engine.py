# Se a biblioteca strands_agents n√£o for encontrada, me avise!
# Estou usando uma estrutura gen√©rica compat√≠vel com requests/ollama para garantir funcionalidade
# caso o SDK tenha sintaxe espec√≠fica que n√£o conhecemos.

import requests
import json
from app.core.config import settings
from app.agent.tools import calculate_tool


class DreamAgent:
    def __init__(self):
        self.model = settings.OLLAMA_MODEL
        self.api_url = f"{settings.OLLAMA_BASE_URL}/api/generate"

        # Prompt de Sistema: Ensina o Agente quem ele √© e como usar ferramentas
        # Prompt de Sistema Refinado
        self.system_prompt = """
        Voc√™ √© um assistente preciso da DreamSquad.
        
        FERRAMENTA DE C√ÅLCULO:
        Se o usu√°rio pedir QUALQUER conta matem√°tica, voc√™ DEVE responder APENAS neste formato:
        CALC: [express√£o matem√°tica]
        
        Exemplos Corretos:
        Usu√°rio: Quanto √© 2 + 2?
        Voc√™: CALC: 2 + 2
        
        Usu√°rio: Raiz de 144
        Voc√™: CALC: math.sqrt(144)
        
        Usu√°rio: 50 vezes 2
        Voc√™: CALC: 50 * 2

        REGRA DE OURO:
        - N√ÉO explique o c√°lculo antes.
        - N√ÉO invente continua√ß√£o de conversa.
        - Se receber o resultado da tool, apenas diga o n√∫mero final ou uma frase curta.
        """

    def process_message(self, user_message: str) -> str:
        """
        Processa a mensagem, verifica se precisa usar ferramenta e retorna a resposta final.
        """
        # 1. Pergunta inicial para a LLM
        full_prompt = f"{self.system_prompt}\n\nUsu√°rio: {user_message}\nAssitente:"

        response_text = self._call_ollama(full_prompt)

        # 2. Verifica se a IA pediu para usar a calculadora (Pattern Matching)
        if "CALC:" in response_text:
            # Extrai a conta (ex: "CALC: 123 * 4") -> "123 * 4"
            expression = response_text.split("CALC:")[1].strip()
            print(f"üßÆ Agente solicitou c√°lculo: {expression}")

            # Usa a Tool que criamos na Etapa 3
            result = calculate_tool(expression)

            # 3. Devolve o resultado para a IA formular a resposta final
            final_prompt = f"{full_prompt}\n{response_text}\nSistema (Resultado da Tool): {result}\nAssitente (responda o usu√°rio com o resultado):"
            final_response = self._call_ollama(final_prompt)
            return final_response

        return response_text

    def _call_ollama(self, prompt: str) -> str:
        """Fun√ß√£o auxiliar para chamar a API do Ollama"""
        payload = {
            "model": self.model,
            "prompt": prompt,
            "stream": False
        }
        try:
            response = requests.post(self.api_url, json=payload)
            response.raise_for_status()
            return response.json().get("response", "")
        except Exception as e:
            return f"Erro na comunica√ß√£o com IA: {e}"


# Inst√¢ncia global do agente
agent = DreamAgent()
