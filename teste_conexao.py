import requests
import json

# Configura√ß√£o simples para testar se o Ollama est√° ouvindo
# Por padr√£o, o Ollama roda na porta 11434
OLLAMA_URL = "http://localhost:11434/api/generate"


def testar_ollama():
    payload = {
        "model": "llama3.2",  # Certifique-se que este √© o modelo que voc√™ baixou
        "prompt": "Responda apenas com a palavra 'FUNCIONOU' se voc√™ estiver me ouvindo.",
        "stream": False
    }

    try:
        print("üì° Tentando conectar com o Ollama local...")
        response = requests.post(OLLAMA_URL, json=payload)
        response.raise_for_status()

        resposta_ia = response.json().get("response", "").strip()
        print(f"ü§ñ Resposta da IA: {resposta_ia}")
        print("‚úÖ Sucesso! O ambiente est√° pronto.")

    except requests.exceptions.ConnectionError:
        print("‚ùå Erro: N√£o foi poss√≠vel conectar ao Ollama.")
        print("Dica: Verifique se o aplicativo do Ollama est√° rodando.")
    except Exception as e:
        print(f"‚ùå Erro inesperado: {e}")


if __name__ == "__main__":
    testar_ollama()
# Para rodar este script, use o comando:
# python teste_conexao.py